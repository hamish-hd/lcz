import geopandas as gpd
import rasterio
import pandas as pd
import numpy as np
from rasterio.mask import mask
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score
from shapely.geometry import mapping
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler

# Load raster image and shapefile
src = rasterio.open('/data/gedi/lcz/final/2023_pcmc.tif')
gdf = gpd.read_file('/data/gedi/lcz/samples_20240228/samples_20240228.shp')

# Print the first few rows of the shapefile data
print(gdf.head())

# Convert shapefile to the same coordinate reference system as the raster
gdf = gdf.to_crs(src.crs)

# Extract pixel values and class labels from the raster
pixel_values_by_band = [[] for _ in range(src.count)]
class_labels = []

for index, row in gdf.iterrows():
    geom = row['geometry']
    out_image, out_transform = mask(src, [mapping(geom)], crop=True)

    for band_num in range(src.count):
        band_values = out_image[band_num, :, :].flatten()
        pixel_values_by_band[band_num].extend(band_values)

    class_labels.extend([row['class']] * len(band_values))

# Create a DataFrame from pixel values and class labels
columns = [f"Band_{i+1}" for i in range(src.count)]
pixel_df = pd.DataFrame(np.array(pixel_values_by_band).T, columns=columns)
pixel_df['ClassLabel'] = class_labels

# Drop rows with NaN in 'Band_1' and fill remaining NaN with 0
pixel_df_cleaned = pixel_df.dropna(subset=['Band_1']).fillna(0)

# Prepare features (X) and target variable (y)
X = pixel_df_cleaned.drop('ClassLabel', axis=1)
y = pixel_df_cleaned['ClassLabel']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Evaluate the model on the test set
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
kappa = cohen_kappa_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("\nClassification Report:\n", classification_rep)
print("\nCohen's Kappa Coefficient:", kappa)

# Feature Importance Analysis
feature_importance = clf.feature_importances_
important_features = X.columns[feature_importance > 0.01]

# Select only important features
X_selected = X[important_features]

# Retrain the model with selected features
X_train_selected, X_test_selected = train_test_split(X_selected, test_size=0.2, random_state=42)
clf_selected = RandomForestClassifier(n_estimators=100, random_state=42)
clf_selected.fit(X_train_selected, y_train)

# Evaluate the model with selected features on the test set
y_pred_selected = clf_selected.predict(X_test_selected)
accuracy_selected = accuracy_score(y_test, y_pred_selected)
classification_rep_selected = classification_report(y_test, y_pred_selected)

print("\nAccuracy with Selected Features:", accuracy_selected)
print("\nClassification Report with Selected Features:\n", classification_rep_selected)

# Hyperparameter Tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train_selected, y_train)

best_params = grid_search.best_params_
clf_tuned = RandomForestClassifier(random_state=42, **best_params)
clf_tuned.fit(X_train_selected, y_train)

y_pred_tuned = clf_tuned.predict(X_test_selected)
accuracy_tuned = accuracy_score(y_test, y_pred_tuned)
classification_rep_tuned = classification_report(y_test, y_pred_tuned)
kappa_tuned = cohen_kappa_score(y_test, y_pred_tuned)

print("\nAccuracy with Tuned Hyperparameters:", accuracy_tuned)
print("\nClassification Report with Tuned Hyperparameters:\n", classification_rep_tuned)
print("\nCohen's Kappa Coefficient with Tuned Hyperparameters:", kappa_tuned)

# Data Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(pixel_df_cleaned.drop('ClassLabel', axis=1))
pixel_df_cleaned_scaled = pd.DataFrame(X_scaled, columns=columns)
pixel_df_cleaned_scaled['ClassLabel'] = pixel_df_cleaned['ClassLabel']
